# Linear Algebra Based Student Performance Analysis

## üéØ Objective
You are tasked with analyzing and transforming a dataset using **Linear Algebra concepts** to derive meaningful insights. The project integrates **vectors, matrices, decompositions, and dimensionality reduction techniques** to give students hands-on practice in mathematical foundations widely applied in **Data Science, AI/ML, and Engineering**.

---

## üìÑ Problem Statement
A research institute has shared a dataset containing **students‚Äô performance scores across multiple subjects**. As a data analyst, the task is to apply **Linear Algebra techniques** to:

1. Represent and manipulate data using vectors and matrices.
2. Perform advanced operations (dot products, cross products, vector projections, norms).
3. Explore matrix decompositions (LU, SVD).
4. Apply dimensionality reduction techniques (PCA & LDA).
5. Interpret eigenvalues and eigenvectors to understand variance in the dataset.

---

## üìå Tasks

### Part A: Vector & Matrix Fundamentals
1. Represent each student‚Äôs subject scores as a **vector**.
2. Compute:
   - Norm-1 and Norm-2 of vectors.
   - Dot product and angle between two students‚Äô score vectors.
   - Cross product (for 3D selected subjects).
3. Find the **projection of one vector onto another**.

### Part B: Matrix Operations
4. Form a **matrix** of students √ó subjects. Perform:
   - Matrix addition and multiplication.
   - Transpose and Inverse (if possible).
   - Determinant.

### Part C: Linear Transformations & Geometry
5. Explain **line, plane, and hyperplane** with respect to dataset dimensions.
6. Show how **dimensionality increases** from 2D ‚Üí 3D ‚Üí higher dimensions with hyperplanes.

### Part D: Eigenvalues & Decomposition
7. Compute the **eigenvalues and eigenvectors** of the covariance matrix.
8. Perform **LU Decomposition** of the dataset matrix.
9. Perform **Singular Value Decomposition (SVD)** and explain its role in dimensionality reduction.

### Part E: Dimensionality Reduction
10. Apply **Principal Component Analysis (PCA)** to reduce the dataset from multiple subjects to 2 dimensions.
11. Apply **Linear Discriminant Analysis (LDA)** to classify students into ‚ÄúAbove Average‚Äù and ‚ÄúBelow Average‚Äù categories.

---

## üõ†Ô∏è Deliverables
- Complete the tasks **theoretically and practically (Python/Excel/Manual calculations)** within the allotted exam time.
- Represented dataset as vectors and matrices.
- Performed vector operations: norms, dot product, angle calculation, cross product, and vector projection.
- Conducted matrix operations: addition, multiplication, transpose, inverse, and determinant.
- Explained linear transformations: line, plane, and hyperplane with dimensionality increase.
- Computed eigenvalues and eigenvectors, and performed LU & SVD decompositions.
- Applied PCA for dimensionality reduction.
- Applied LDA for student classification (Above Average & Below Average).

